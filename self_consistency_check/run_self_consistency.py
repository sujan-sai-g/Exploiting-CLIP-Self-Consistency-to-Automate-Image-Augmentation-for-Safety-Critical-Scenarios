import argparse
import torch 
import random
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report
import shutil
import os

from create_embeddings import embeddings_gen
from create_metadata import MetadataGen
from crop_pedestrians import object_cropper
from create_gt_bbox_csv import csv_gen
from create_specification_csv import create_gt_metadata_csv, clean_up_gt_metadata
from create_merge_csv import merge_files

random.seed(100)
torch.manual_seed(100)
np.random.seed(100)


def filter_data(args):
    df = pd.read_csv(args.csv_outputs + "full_merge_file.csv")
    df = df.dropna()
    attributes_list = ['gender', 'age', 'skin-color', 'shirt-color', 'action']
    for attribute in attributes_list:
        cr = classification_report(df[attribute + '_gt'], df[attribute])
        print(cr)

    filtered_df = df[(df['gender'] == df['gender_gt'])
                     & (df['age'] == df['age_gt'])
                     & (df['skin-color'] == df['skin-color_gt'])
                     & (df['shirt-color'] == df['shirt-color_gt'])
                     & (df['action'] == df['action_gt'])]

    filtered_df['size'] = (filtered_df['x2_list'] - filtered_df['x1_list']) * (filtered_df['y2_list'] - filtered_df['y1_list'])

    filtered_df.to_csv(args.csv_outputs + "filtered_sample_from_deliberate_after_matching.csv")
    print(f"length of augmented set {len(df)}")
    print(f"length of filtered augmented set {len(filtered_df)}")

    return filtered_df


def copy_filtered_data(filtered_df):
    # Define the path to the directory where you want to copy the images
    target_directory_path = 'path-to-save-samples/'
    generated_image_directory = 'path-to-save-samples/'
    # Ensure the target directory exists, create if it doesn't
    if not os.path.exists(target_directory_path):
        os.makedirs(target_directory_path)    

    # Iterate over the DataFrame's column containing the image paths
    for image_path in filtered_df['Filename']:
        print(image_path)
        substring = "00000-" + image_path
        matched_file = [
            f for f in os.listdir(generated_image_directory) if substring in f
        ]
        print(matched_file)
        # Define the target path for the image
        target_path = os.path.join(target_directory_path, os.path.basename(matched_file[0]))
        
        # Copy the image to the target directory
        shutil.copy(generated_image_directory + matched_file[0], target_path)

# def check_passthrough_rate():
#     full_df = pd.read_excel("")
#     filtered_df = pd.read_csv("")

#     print(full_df)
#     print(filtered_df)

#     mask = full_df.Column2 == 0
#     print(mask)
#     filenames = full_df.Filename[mask].to_list()
#     x = filtered_df['Filename'].isin(filenames)
#     print(x.value_counts())
#     print(x[x == True])


def main():

    parser = argparse.ArgumentParser()
    parser.add_argument('--image_crop_path', type=str, default="")
    parser.add_argument('--image_embeddings_path', type=str, default="")
    parser.add_argument('--ontology_path', type=str, default="")
    parser.add_argument('--csv_outputs', type=str, default="/csv_outputs/")
    parser.add_argument('--generated_image_folder_path', type=str, default="")
    parser.add_argument('--generated_mask_position_folder_path', type=str, default="")

    args = parser.parse_args()

    if torch.cuda.is_available():
        args.device = "cuda:0"
    else:
        args.device = "cpu"

    create gt csvs
    print("creating GT csv")
    csv_gen(args)

    # create image crops
    print("Cropping the inpainted pedestrians")
    object_cropper(args)

    # create image embeddings
    print("Creating the embeddings for inpainted pedestrians")
    embeddings_gen(args)

    # create metadata for the crops
    print("Creating the metadata using embeddings")

    mg = MetadataGen(args)
    mg.run()

    # create csv containing specification metadata from prompts
    print("Creating the specification csv")

    create_gt_metadata_csv(args)
    clean_up_gt_metadata(args)
    
    print("merge all csvs")
    merge_files(args)

    print("performing self-consistency check")
    filter_data(args)


if __name__ == '__main__':
    main()